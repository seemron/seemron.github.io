---
layout: base.njk
pageTitle: "Topic Summaries | Seemron Neupane"
permalink: /topic_summaries/
extraScripts: '<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>'
---
        <div class="row justify-content-center">
            <div class="col-lg-8">
                <p class="aligned-text">
                    Below are portions of scribble notes for various topics that I have come across in research that I
                    try to organize and record for future reference.
                </p>

                <div class="subheaders">Mathy Notes</div>
                <details>
                    <summary>Johnson-Lindenstrauss Lemma</summary>
                    <div class="content">
                        <p><strong>Lemma Statement</strong>
                            \[
                            d()
                            \]
                            bi-Lipschitz statement</p>
                        <p><strong>Two Proofs for JL Lemma</strong>
                        <p><i>Proof 1: Original </i></p>
                        <p><i>Proof 2: Dasgupta and Gupta (2002)</i></p>
                        </p>
                        <p><strong>Seminal Papers</strong>
                        <p><i>The Johnson-Lindenstrauss Lemma Is Optimal for Linear Dimensionality Reduction</i></p>
                        <p><i>Optimality of the Johnson-Lindenstrauss Lemma</i></p>
                        </p>
                    </div>
                </details>

                <details>
                    <summary>Interpretability (The "Traditional" Kind)</summary>
                    <div class="content">
                        <p><strong>Integrated Gradients</strong>
                        </p>
                        <p><strong>SHAPley Values</strong>
                        </p>
                    </div>
                </details>

                <details>
                    <summary>Manifold Learning</summary>
                    <div class="content">
                    </div>
                </details>

                <details>
                    <summary>Markov Chains</summary>
                    <div class="content">
                    </div>
                </details>

                <details>
                    <summary>Sum-of-Squares</summary>
                    <div class="content">
                        <p><strong>Reference:</strong> <a href="https://www.sumofsquares.org/public/index.html">Proofs,
                                beliefs, and algorithms through the lens of sum-of-squares (by Boaz Barak and David
                                Steurer)</a></p>
                    </div>
                </details>

                <details>
                    <summary>\(k\)-means++</summary>
                    <div class="content">
                    </div>
                </details>

                <details>
                    <summary>Neural Tangent Kernels</summary>
                    <div class="content">
                    </div>
                </details>

                <details>
                    <summary>Positive & Unlabeled (PU) Learning</summary>
                    <div class="content">
                    </div>
                </details>

                <details>
                    <summary>Kamada-Kawai Formulation of Multi-Dimensional Scaling</summary>
                    <div class="content">
                        <p><strong>Reference:</strong> <a href="https://arxiv.org/pdf/2311.17840">A quasi-polynomial
                                time algorithm for Multi-Dimensional Scaling via LP hierarchies (Bakshi et al.,
                                2023)</a>, and conversations with <a href="https://njbergam.github.io/">Noah Bergam</a>
                        </p>
                    </div>
                </details>

                <details>
                    <summary>Tail Bounds for Matrix Martingales</summary>
                    <div class="content">
                        <p><strong>Reference:</strong> Joel Tropp's Papers</p>
                    </div>
                </details>

                <details>
                    <summary>Sufficient Statistics</summary>
                    <div class="content">
                    </div>
                </details>

                <div class="subheaders">More Empirics-Centered Notes</div>
                <details>
                    <summary>Flash Attention</summary>
                    <div class="content">
                        <p>

                        </p>
                    </div>
                </details>

                <details>
                    <summary>Mamba (S4) Model</summary>
                    <div class="content">
                        <p>

                        </p>
                    </div>
                </details>
            </div>
            <div class="col-lg-8">
                <div class="subheaders">Other Notes (PDFs)</div>
                <ul>
                    <li> <a href="" class="link">LaTeXed notes</a> for Machine Learning Theory</li>
                    <li> <a href="" class="link">LaTeXed notes</a> for Statistical Inference Theory</li>
                    <li> <a href="" class="link">LaTeXed notes</a> for Advanced Algorithms</li>
                    <li> <a href="" class="link">LaTeXed notes</a> for Analysis of Algorithms</li>
                    <li> <a href="" class="link">LaTeXed notes</a> for Computer Science Theory</li>
                    <li> <a href="" class="link">LaTeXed notes</a> for Bare-bones Basics of Learning Theory</li>
                </ul>
            </div>
        </div>
